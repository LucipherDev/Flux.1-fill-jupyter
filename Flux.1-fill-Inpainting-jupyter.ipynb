{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Install</h1></center>\n",
        "\n",
        "%cd /content\n",
        "!git clone -b totoro6 https://github.com/LucipherDev/ComfyUI /content/TotoroUI\n",
        "!git clone -b totoro https://github.com/LucipherDev/ComfyUI-GGUF /content/TotoroUI/custom_nodes/TotoroUI-GGUF\n",
        "!git clone -b totoro https://github.com/LucipherDev/ComfyUI-Inpaint-CropAndStitch /content/TotoroUI/custom_nodes/TotoroUI-Inpaint-CropAndStitch\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.28.post2\n",
        "!pip install -q -r /content/TotoroUI/custom_nodes/TotoroUI-GGUF/requirements.txt\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "import nodes\n",
        "\n",
        "if not nodes.load_custom_node(\"custom_nodes/TotoroUI-GGUF\"):\n",
        "  raise Exception(\"Failed to load GGUF custom node\")\n",
        "\n",
        "if not nodes.load_custom_node(\"custom_nodes/TotoroUI-Inpaint-CropAndStitch\"):\n",
        "  raise Exception(\"Failed to load Inpaint-CropAndStitch custom node\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k3aTOrdb8HxC"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Load Models</h1></center>\n",
        "\n",
        "import torch\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from totoro_extras import nodes_differential_diffusion\n",
        "\n",
        "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
        "UnetLoaderGGUF = NODE_CLASS_MAPPINGS[\"UnetLoaderGGUF\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "DifferentialDiffusion = nodes_differential_diffusion.NODE_CLASS_MAPPINGS[\"DifferentialDiffusion\"]()\n",
        "\n",
        "print(f\"Downloading Flux1-fill-dev-Q4_K_S...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/YarvixPA/FLUX.1-Fill-dev-gguf/resolve/main/flux1-fill-dev-Q4_K_S.gguf -d /content/TotoroUI/models/unet -o flux1-fill-dev-Q4_K_S.gguf\n",
        "\n",
        "print(\"Downloading VAE...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
        "\n",
        "print(\"Downloading Clips...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n",
        "\n",
        "with torch.inference_mode():\n",
        "    print(\"Loading Clips...\")\n",
        "    clip = DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "    print(\"Loading VAE...\")\n",
        "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "    print(f\"Loading Flux1-fill-dev-Q4_K_S...\")\n",
        "    unet = UnetLoaderGGUF.load_unet(f\"flux1-fill-dev-Q4_K_S.gguf\")[0]\n",
        "    unet = DifferentialDiffusion.apply(unet)[0]\n",
        "\n",
        "    unet_f, clip_f = unet, clip\n",
        "\n",
        "print(\"All Models Loaded!\")\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab import files, output\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image, ImageOps\n",
        "import io\n",
        "import base64\n",
        "\n",
        "import nodes\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro_extras import nodes_mask\n",
        "from totoro import model_management\n",
        "\n",
        "CLIPTextEncodeFlux = nodes_flux.NODE_CLASS_MAPPINGS[\"CLIPTextEncodeFlux\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "InpaintModelConditioning = NODE_CLASS_MAPPINGS[\"InpaintModelConditioning\"]()\n",
        "ImageToMask = nodes_mask.NODE_CLASS_MAPPINGS[\"ImageToMask\"]()\n",
        "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "MaskToImage = nodes_mask.NODE_CLASS_MAPPINGS[\"MaskToImage\"]()\n",
        "InpaintCrop = NODE_CLASS_MAPPINGS[\"InpaintCrop\"]()\n",
        "InpaintStitch = NODE_CLASS_MAPPINGS[\"InpaintStitch\"]()\n",
        "GrowMask = nodes_mask.NODE_CLASS_MAPPINGS[\"GrowMask\"]()\n",
        "ImageCompositeMasked = nodes_mask.NODE_CLASS_MAPPINGS[\"ImageCompositeMasked\"]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mLGPKWvopwnC"
      },
      "outputs": [],
      "source": [
        "# @markdown <center><h1>Functions</h1></center>\n",
        "\n",
        "# @markdown <ul><li><h2>Inpaint Mask</h2></ul>\n",
        "\n",
        "input_image = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "use_mask_from_image = False # @param {\"type\":\"boolean\"}\n",
        "mask_dir = \"/content/inpaint_mask.png\" # @param {\"type\":\"string\"}\n",
        "draw_mask = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "# @markdown <ul><li><h2>Crop and Stitch</h2></li></li></ul>\n",
        "\n",
        "context_expand_pixels = 20 # @param {\"type\":\"slider\",\"min\":0,\"max\":256,\"step\":1}\n",
        "context_expand_factor = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":100,\"step\":0.01}\n",
        "fill_mask_holes = True # @param {\"type\":\"boolean\"}\n",
        "invert_mask = False # @param {\"type\":\"boolean\"}\n",
        "crop_mode = \"ranged size\" # @param [\"ranged size\", \"forced size\", \"free size\"] {\"type\":\"string\"}\n",
        "rescale_algorithm = \"bislerp\" # @param [\"nearest\", \"bilinear\", \"bicubic\", \"bislerp\", \"lanczos\", \"box\", \"hamming\"]  {\"type\":\"string\"}\n",
        "force_width =  1024 # @param {\"type\":\"slider\",\"min\":512,\"max\":1024,\"step\":1}\n",
        "force_height =  1024 # @param {\"type\":\"slider\",\"min\":512,\"max\":1024,\"step\":1}\n",
        "rescale_factor = 1 # @param {\"type\":\"slider\",\"min\":0.01,\"max\":100,\"step\":0.01}\n",
        "padding = 8 # @param [\"8\",\"16\",\"32\",\"64\",\"128\",\"256\",\"512\"] {\"type\":\"raw\"}\n",
        "min_width = 512 # @param {\"type\":\"slider\",\"min\":256,\"max\":512,\"step\":1}\n",
        "min_height = 512 # @param {\"type\":\"slider\",\"min\":256,\"max\":512,\"step\":1}\n",
        "max_width = 768 # @param {\"type\":\"slider\",\"min\":768,\"max\":1024,\"step\":1}\n",
        "max_height = 768 # @param {\"type\":\"slider\",\"min\":768,\"max\":1024,\"step\":1}\n",
        "\n",
        "paint_interface = f\"\"\"\n",
        "<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css');body{{background-color:#2d2d2d;font-family:Arial,sans-serif;color:#fff;margin:0;display:flex;justify-content:center;align-items:center}}#toolbar{{display:flex;flex-wrap:wrap;justify-content:center;align-items:center;padding:10px 0;margin:10px auto;background-color:#3c3f41;border-radius:8px;width:100%;max-width:512px;box-shadow:0 4px 10px rgba(0,0,0,0.3)}}.button{{padding:10px 15px;margin:5px;font-size:14px;cursor:pointer;border-radius:5px;color:#fff;background-color:#5e5e5e;border:0;font-weight:bold;transition:.3s}}.button:hover{{background-color:#757575}}.button.active{{background-color:#fff7e0;color:#202124}}.button:disabled{{cursor:default;background-color:#a9a9a9}}.slider-container{{display:flex;align-items:center;margin:10px 0}}#brushSizeSlider{{margin-left:10px;cursor:pointer;width:200px}}#canvasContainer{{margin:20px auto;border:2px solid #5e5e5e;border-radius:8px;position:relative;display:inline-block;width:512px;height:512px}}canvas{{display:block;cursor:crosshair}}#imageOverlay{{position:absolute;top:0;left:0;pointer-events:none;opacity:.5;z-index:0}}</style>\n",
        "<div id=\"toolbar\">\n",
        "<button class=\"button active\" id=\"drawButton\" onclick=\"setTool('draw')\"><i class=\"fa fa-paint-brush\"></i> Draw</button>\n",
        "<button class=\"button\" id=\"eraseButton\" onclick=\"setTool('erase')\"><i class=\"fa fa-eraser\"></i> Erase</button>\n",
        "<button class=\"button\" id=\"clearButton\" onclick=\"clearCanvas()\"><i class=\"fa fa-trash\"></i> Clear</button>\n",
        "<button class=\"button\" id=\"saveButton\" onclick=\"saveCanvas()\"><i class=\"fa fa-check\"></i> Save</button>\n",
        "<button class=\"button\" id=\"undoButton\" onclick=\"undo()\" disabled><i class=\"fa fa-undo\"></i></button>\n",
        "<button class=\"button\" id=\"redoButton\" onclick=\"redo()\" disabled><i class=\"fa fa-rotate-right\"></i></button>\n",
        "<div class=\"slider-container\">\n",
        "<label for=\"brushSizeSlider\">Brush Size: <span id=\"brushSizeDisplay\">20</span></label>\n",
        "<input id=\"brushSizeSlider\" type=\"range\" min=\"1\" max=\"100\" value=\"20\">\n",
        "</div>\n",
        "</div>\n",
        "<div id=\"canvasContainer\">\n",
        "<img id=\"imageOverlay\" />\n",
        "<canvas id=\"paintCanvas\"></canvas>\n",
        "</div>\n",
        "<script>const canvas=document.getElementById('paintCanvas');const ctx=canvas.getContext('2d');const imageOverlay=document.getElementById('imageOverlay');const canvasContainer=document.getElementById('canvasContainer');const brushSizeSlider=document.getElementById('brushSizeSlider');const brushSizeDisplay=document.getElementById('brushSizeDisplay');let tool='draw';let drawing=false;let brushSize=20;function highlightActiveButton(tool){{document.querySelectorAll('.button').forEach(button=>button.classList.remove('active'));if(tool==='draw'){{document.getElementById('drawButton').classList.add('active');}}else if(tool==='erase'){{document.getElementById('eraseButton').classList.add('active');}}}}\n",
        "const backgroundImage=new Image();backgroundImage.src=\"/files/{input_image}\";backgroundImage.onload=function(){{const aspectRatio=backgroundImage.width/backgroundImage.height;let width,height;if(backgroundImage.width>backgroundImage.height){{height=512;width=height*aspectRatio;}}else{{width=512;height=width/aspectRatio;}}\n",
        "canvas.width=width;canvas.height=height;imageOverlay.width=width;imageOverlay.height=height;canvasContainer.style.width=`${{width}}px`;canvasContainer.style.height=`${{height}}px`;ctx.fillStyle='{'white' if invert_mask else 'black'}';ctx.fillRect(0,0,canvas.width,canvas.height);imageOverlay.src=backgroundImage.src;}};brushSizeSlider.addEventListener('input',function(event){{brushSize=event.target.value;brushSizeDisplay.textContent=brushSize;}});function setTool(selectedTool){{tool=selectedTool;highlightActiveButton(tool);}}\n",
        "canvas.addEventListener('mousedown',()=>{{drawing=true;}});canvas.addEventListener('mouseup',()=>{{drawing=false;ctx.beginPath();}});canvas.addEventListener('mousemove',draw);function draw(event){{if(!drawing)return;const rect=canvas.getBoundingClientRect();const x=event.clientX-rect.left;const y=event.clientY-rect.top;ctx.lineWidth=brushSize;ctx.lineCap='round';ctx.globalCompositeOperation='source-over';if(tool==='draw'){{ctx.strokeStyle='{'black' if invert_mask else 'white'}';}}else if(tool==='erase'){{ctx.strokeStyle='{'white' if invert_mask else 'black'}';}}\n",
        "ctx.lineTo(x,y);ctx.stroke();ctx.beginPath();ctx.moveTo(x,y);}}\n",
        "function clearCanvas(){{ctx.globalCompositeOperation='source-over';ctx.fillStyle='{'white' if invert_mask else 'black'}';ctx.fillRect(0,0,canvas.width,canvas.height);ctx.beginPath();}}\n",
        "function saveCanvas(){{const dataURL=canvas.toDataURL('image/png');google.colab.kernel.invokeFunction('notebook.save_mask',[dataURL],{{}});}}\n",
        "const undoStack=[];const redoStack=[];function updateUndoRedoButtons(){{document.getElementById('undoButton').disabled=undoStack.length===0;document.getElementById('redoButton').disabled=redoStack.length===0;}}\n",
        "function saveState(){{undoStack.push(canvas.toDataURL());redoStack.length=0;updateUndoRedoButtons();}}\n",
        "function undo(){{if(undoStack.length===0)return;redoStack.push(canvas.toDataURL());const previousState=undoStack.pop();const img=new Image();img.src=previousState;img.onload=function(){{ctx.clearRect(0,0,canvas.width,canvas.height);ctx.drawImage(img,0,0);}};updateUndoRedoButtons();}}\n",
        "function redo(){{if(redoStack.length===0)return;undoStack.push(canvas.toDataURL());const nextState=redoStack.pop();const img=new Image();img.src=nextState;img.onload=function(){{ctx.clearRect(0,0,canvas.width,canvas.height);ctx.drawImage(img,0,0);}};updateUndoRedoButtons();}}\n",
        "canvas.addEventListener('mousedown',()=>{{saveState();drawing=true;}});canvas.addEventListener('mouseup',()=>{{drawing=false;ctx.beginPath();}});updateUndoRedoButtons();</script>\n",
        "\"\"\"\n",
        "\n",
        "def save_mask(data_url):\n",
        "  global mask_dir\n",
        "\n",
        "  header, encoded = data_url.split(\",\", 1)\n",
        "  binary_data = base64.b64decode(encoded)\n",
        "  img = Image.open(io.BytesIO(binary_data))\n",
        "  mask_dir = f\"/content/inpaint_mask_{''.join(str(random.randint(0, 9)) for _ in range(5))}.png\"\n",
        "  img.save(mask_dir)\n",
        "\n",
        "  print(f\"Mask saved: {mask_dir}\")\n",
        "\n",
        "def save_image(decoded, path, name, download=False):\n",
        "  full_path = os.path.abspath(os.path.join(path, name))\n",
        "  Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save( full_path)\n",
        "\n",
        "  img = Image.open(full_path)\n",
        "  display(img)\n",
        "\n",
        "  if download:\n",
        "    files.download(full_path)\n",
        "\n",
        "def img_tensor_to_np(img_tensor):\n",
        "  img_tensor = img_tensor.clone() * 255.0\n",
        "  return img_tensor.squeeze().numpy().astype(np.uint8)\n",
        "\n",
        "def img_np_to_tensor(img_np_list):\n",
        "  return torch.from_numpy(img_np_list.astype(np.float32) / 255.0).unsqueeze(0)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(pos_prompt, neg_prompt, fixed_seed, guidance, steps, cfg, sampler_name, scheduler, denoise, use_crop_stitch, mask_expand, mask_blur, mask_blend, batch_size, auto_download):\n",
        "  global unet, clip, unet_f, clip_f\n",
        "\n",
        "  print(\"Prompt Received\")\n",
        "\n",
        "  pos_cond = CLIPTextEncodeFlux.encode(clip_f, pos_prompt, pos_prompt, guidance)[0]\n",
        "  neg_cond = CLIPTextEncodeFlux.encode(clip_f, neg_prompt, neg_prompt, guidance)[0]\n",
        "\n",
        "  image, mask = LoadImage.load_image(input_image)\n",
        "  image_np = img_tensor_to_np(image)\n",
        "  img = Image.fromarray(image_np)\n",
        "\n",
        "  if not use_mask_from_image:\n",
        "    mask_image = LoadImage.load_image(mask_dir)[0]\n",
        "    mask_np = img_tensor_to_np(mask_image)\n",
        "    mask_img = Image.fromarray(mask_np)\n",
        "    mask_img = mask_img.resize((img.width, img.height), Image.Resampling.LANCZOS)\n",
        "    mask_np = np.array(mask_img).astype(np.uint8)\n",
        "    mask_image = img_np_to_tensor(mask_np)\n",
        "\n",
        "    mask = ImageToMask.image_to_mask(mask_image, \"red\")[0]\n",
        "\n",
        "  if use_crop_stitch:\n",
        "    mask = GrowMask.expand_mask(mask, mask_expand, True)[0]\n",
        "\n",
        "    stitch, image, mask = InpaintCrop.inpaint_crop_single_image(image, mask, context_expand_pixels, context_expand_factor, fill_mask_holes, mask_blur, invert_mask, mask_blend, crop_mode, rescale_algorithm, force_width, force_height, rescale_factor, padding, min_width, min_height, max_width, max_height)\n",
        "\n",
        "  display(HTML(f\"\"\"\n",
        "  <div style=\"display: flex; gap: 10px;\">\n",
        "      {\"\".join(f'<img src=\"data:image/png;base64,{base64.b64encode(io.BytesIO(Image.fromarray(img).save((buf:=io.BytesIO()), format=\"PNG\") or buf.getvalue()).getvalue()).decode(\"utf-8\")}\" style=\"width: 512px;\">' for img in [img_tensor_to_np(image), img_tensor_to_np(MaskToImage.mask_to_image(mask)[0])])}\n",
        "  </div>\n",
        "  \"\"\"))\n",
        "\n",
        "  pos_cond, neg_cond, latent_image = InpaintModelConditioning.encode(pos_cond, neg_cond, image, vae, mask, True)\n",
        "\n",
        "  for i in range(0, batch_size):\n",
        "    if fixed_seed == 0:\n",
        "      seed = random.randint(0, 18446744073709551615)\n",
        "    else:\n",
        "      seed = fixed_seed\n",
        "\n",
        "    print(\"Seed:\", seed)\n",
        "\n",
        "    sample = KSampler.sample(unet_f, seed, steps, cfg, sampler_name, scheduler, pos_cond, neg_cond, latent_image, denoise)[0]\n",
        "    model_management.soft_empty_cache()\n",
        "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "    decoded = ImageCompositeMasked.composite(image, decoded, 0, 0, True, mask)[0]\n",
        "\n",
        "    if use_crop_stitch:\n",
        "      decoded = InpaintStitch.inpaint_stitch_single_image(stitch, decoded, rescale_algorithm)[0]\n",
        "\n",
        "    save_image(decoded, \"/content\", f\"flux_fill_{seed}_{i}.png\", auto_download)\n",
        "\n",
        "if draw_mask:\n",
        "  output.register_callback('notebook.save_mask', save_mask)\n",
        "  display(HTML(paint_interface))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ur9TmMNwC2kR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Inpaint</h1></center>\n",
        "\n",
        "positive_prompt = \"\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"watermark, text, ugly, deformed, low quality\" # @param {\"type\":\"string\"}\n",
        "fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "guidance = 30 # @param {\"type\":\"slider\",\"min\":0,\"max\":50,\"step\":0.5}\n",
        "steps = 20 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "cfg = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":100,\"step\":0.1}\n",
        "denoise = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "use_crop_stitch = True # @param {\"type\":\"boolean\"}\n",
        "mask_expand = 0 # @param {\"type\":\"slider\",\"min\":-256,\"max\":256,\"step\":0.1}\n",
        "mask_blur = 16 # @param {\"type\":\"slider\",\"min\":0,\"max\":64,\"step\":0.1}\n",
        "mask_blend = 16 # @param {\"type\":\"slider\",\"min\":0,\"max\":32,\"step\":0.1}\n",
        "batch_size = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "generate(positive_prompt, negative_prompt, fixed_seed, guidance, steps, cfg, sampler_name, scheduler, denoise, use_crop_stitch, mask_expand, mask_blur, mask_blend, batch_size, auto_download)"
      ]
    }
  ]
}